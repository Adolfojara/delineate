#! /usr/bin/env python
# -*- coding: utf-8 -*-

import os
import sys
import json
import argparse
import collections
import json
import itertools
from delineate import utility
from delineate import model

"""
Summarize DELINEATE results.
"""

__prog__ = os.path.basename(__file__)
__author__ = 'Jeet Sukumaran and Mark T. Holder'
__copyright__ = 'Copyright (C) 2019 Jeet Sukumaran and Mark T. Holder.'


def summarize_conspecificity(
        args,
        results_d,
        partitions_d,
        logger,
        ):
    try:
        all_taxa_labels = results_d["lineages"]
    except KeyError:
        all_taxa_labels = set(itertools.chain.from_iterable(partitions_d[0]["species_leafsets"]))
    species_constrained_lineage_map = results_d["species_constraints"]["species_constrained_lineage_map"]
    if not args.quiet:
        logger.info("{} taxa defined in results file: {}".format(len(all_taxa_labels), ", ".join("'{}'".format(t) for t in sorted(all_taxa_labels))))
    total_cumulative_probability = partitions_d[-1]["constrained_cumulative_probability"]
    if not args.quiet:
        logger.info("{} partitions found in results file, with total constrained cumulative probability of {}".format(
            len(partitions_d),
            total_cumulative_probability,
            ))
    conspecific_taxa_labels = args.taxon_label
    if args.taxon_label[0] == "-":
        if not args.quiet:
            logger.info("Reading candidate taxa from standard input")
        conspecific_taxa_labels = []
        for line in sys.stdin:
            if line:
                conspecific_taxa_labels.append(line.strip())
    elif args.taxon_label[0].startswith("file://"):
        fpath = os.path.expandvars(os.path.expandargs(args.taxon_label[7:]))
        if not args.quiet:
            logger.info("Reading candidate taxa from file: '{}'".format(fpath))
        conspecific_taxa_labels = []
        with open(fpath) as taxf:
            for line in taxf:
                if line:
                    conspecific_taxa_labels.append(line.strip())
    else:
        if not args.quiet:
            logger.info("Reading candidate taxa from arguments")
        conspecific_taxa_labels = args.taxon_label
    if not conspecific_taxa_labels:
        logger.error("ERROR: Candidate conspecific taxa not defined or read in any source")
        sys.exit(1)
    conspecific_taxa_labels = sorted(set(conspecific_taxa_labels))
    # if len(conspecific_taxa_labels) == 1:
    #     logger.error("ERROR: At least two conspecific taxa must be defined, but only one given: '{}'".format(
    #         conspecific_taxa_labels[0]))
    #     sys.exit(1)
    if len(conspecific_taxa_labels) == 1:
        desc_noun = "taxon"
    else:
        desc_noun = "taxa"
    if not args.quiet:
        logger.info("{} candidate {} defined: {}".format(
            len(conspecific_taxa_labels),
            desc_noun,
            ", ".join("'{}'".format(t) for t in conspecific_taxa_labels)))
    not_found = []
    for ct in conspecific_taxa_labels:
        if ct not in all_taxa_labels:
            not_found.append(ct)
    if not_found:
        logger.error("ERROR: {} of {} {} not defined in results: {}".format(
            len(not_found),
            len(conspecific_taxa_labels),
            desc_noun,
            ", ".join("'{}'".format(t) for t in not_found)))
        sys.exit(1)
    conspecific_probabilities = []
    new_species_probabilities = []
    existing_species_probabilities = []
    conspecifics_in_confidence_interval = 0
    conspecifics_not_in_confidence_interval = 0
    new_spp_in_confidence_interval = 0
    new_spp_not_in_confidence_interval = 0
    for partition_idx, partition in enumerate(partitions_d):
        is_conspecific = True
        for species_label in partition["species_leafsets"]:
            species_leafset = partition["species_leafsets"][species_label]
            s = set(species_leafset)
            num_in_leafset = 0
            for ct in conspecific_taxa_labels:
                if ct in s:
                    num_in_leafset += 1
            if num_in_leafset > 0 and num_in_leafset < len(conspecific_taxa_labels):
                is_conspecific = False
                break
            elif num_in_leafset == len(conspecific_taxa_labels):
                break
        if is_conspecific:
            partition_probability = partition["constrained_probability"]
            conspecific_probabilities.append(partition_probability)
            if partition["is_in_confidence_interval"]:
                conspecifics_in_confidence_interval += 1
            else:
                conspecifics_not_in_confidence_interval += 1
            if species_label in species_constrained_lineage_map:
                existing_species_probabilities.append(partition_probability)
            else:
                new_species_probabilities.append(partition_probability)
    total_marginal_probability_of_conspecificity = sum(conspecific_probabilities)
    if not args.quiet:
        if len(conspecific_taxa_labels) > 1:
            logger.info("{} out of {} partitions found with candidate taxa conspecific".format(
                len(conspecific_probabilities),
                len(partitions_d),
                ))
            logger.info("Marginal constrained probability of candidate taxa conspecificity: {}".format(total_marginal_probability_of_conspecificity))
        total_probability_of_new_species = sum(new_species_probabilities)
        total_probability_of_existing_species = sum(existing_species_probabilities)
        logger.info("Marginal constrained probability of candidate {} being collectively *part* (i.e., non-exclusively) of a new species: {}".format(desc_noun, total_probability_of_new_species))
        logger.info("Marginal constrained probability of candidate {} being collectively *part* (i.e., non-exclusively) of a predefined species: {}".format(desc_noun, total_probability_of_existing_species))
        if total_cumulative_probability + 1e-8 < 1.0:
            logger.warning("WARNING: cumulative constrained probability in results file is only {} --- not all partitions might have been included, and probability summarizations reported should not be considered as accurate".format(total_cumulative_probability))

    d = {
        "total_marginal_probability_of_conspecificity": total_marginal_probability_of_conspecificity,
        "total_marginal_probability_of_new_species": total_probability_of_new_species,
        "total_marginal_probability_of_existing_species": total_probability_of_new_species,
    }
    return d

def main():
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("-q", "--quiet",
            action="store_true",
            default=False,
            help="Run quietly.")
    parser.add_argument("-r", "--results-file",
            action="store",
            help="Path to results data (JSON).")
    parser.add_argument("taxon_label",
            metavar="TAXON-LABEL",
            nargs="+",
            help="Labels of taxa. Specify '-' to read from standard input or 'file://' to read from file.",)

    args = parser.parse_args()
    # controller.is_quiet = getattr(args, "quiet", True)
    if args.results_file is None:
        sys.exit("Need to specify path to DELINEATE JSON-format results file")
    results_file = os.path.expanduser(os.path.expandvars(args.results_file))
    logger = utility.RunLogger(name="delineate-summarize",
            is_include_name=True,
            is_include_timestamp=False,
            log_to_stderr=True,
            stderr_logging_level=utility.logging.INFO,
            is_log_to_file=False,
            file_logging_level=utility.logging.INFO,
            )
    if not os.path.exists(results_file):
        logger.error("ERROR: File not found: '{}'".format(results_file))
        sys.exit(1)
    with open(results_file) as src:
        results_d = json.load(src)
    try:
        partitions_d = results_d["partitions"]
    except KeyError:
        logger.error("ERROR: 'partitions' key not found in results file.")
        sys.exit(1)
    if len(partitions_d) < 0:
        logger.error("ERROR: No data under 'partitions' key")
        sys.exit(1)

    d = summarize_conspecificity(
            args=args,
            results_d=results_d,
            partitions_d=partitions_d,
            logger=logger,
            )

if __name__ == '__main__':
    main()
